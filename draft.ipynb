{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jElLULrDhQZR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "g4Wzg69bnwK2",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "TensorFlow version: 2.2.0\nEager execution: True\n"
        }
      ],
      "source": [
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = \"gat\"\n",
        "hidden_units = \"16,16\"\n",
        "heads = \"8,8,1\"\n",
        "epochs = 5\n",
        "lr = 0.1\n",
        "dropout = 0.2\n",
        "file_dir = '/Users/lsj/Downloads/DeepInf-homework/weibo'\n",
        "batch = 1024\n",
        "train_ratio = 75\n",
        "vaild_ratio = 12.5\n",
        "instance_normalization = True\n",
        "use_vertex_feature = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_w2v_feature(file, max_idx=0):\n",
        "    with open(file, \"rb\") as f:\n",
        "        nu = 0\n",
        "        for line in f:\n",
        "            content = line.strip().split()\n",
        "            nu += 1\n",
        "            if nu == 1:\n",
        "                n, d = int(content[0]), int(content[1])\n",
        "                feature = [[0.] * d for i in range(max(n, max_idx + 1))]\n",
        "                continue\n",
        "            index = int(content[0])\n",
        "            while len(feature) <= index:\n",
        "                feature.append([0.] * d)\n",
        "            for i, x in enumerate(content[1:]):\n",
        "                feature[index][i] = float(x)\n",
        "    for item in feature:\n",
        "        assert len(item) == d\n",
        "    return np.array(feature, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "graphs = np.load(os.path.join(file_dir, \"adjacency_matrix.npy\")).astype(np.float32)\n",
        "# self-loop trick, the input graphs should have no self-loop\n",
        "identity = np.identity(graphs.shape[1])\n",
        "graphs += identity\n",
        "graphs[graphs != 0] = 1.0\n",
        "if model == \"gat\":\n",
        "   graphs = graphs.astype(np.dtype('B'))\n",
        "elif model == \"gcn\":\n",
        "    # normalized graph laplacian for GCN: D^{-1/2}AD^{-1/2}\n",
        "    for i in range(len(graphs)):\n",
        "        graph = graphs[i]\n",
        "        d_root_inv = 1. / np.sqrt(np.sum(graph, axis=1))\n",
        "        graph = (graph.T * d_root_inv).T * d_root_inv\n",
        "        graphs[i] = graph\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "\n",
        "# wheather a user has been influenced\n",
        "# wheather he/she is the ego user\n",
        "influence_features = np.load(\n",
        "                os.path.join(file_dir, \"influence_feature.npy\")).astype(np.float32)\n",
        "\n",
        "labels = np.load(os.path.join(file_dir, \"label.npy\"))\n",
        "\n",
        "vertices = np.load(os.path.join(file_dir, \"vertex_id.npy\"))\n",
        "\n",
        "graphs, influence_features, labels,vertices = sklearn.utils.shuffle(\n",
        "                        graphs, influence_features,\n",
        "                        labels, vertices,\n",
        "                        random_state=47)\n",
        "\n",
        "vertex_features = np.load(os.path.join(file_dir, \"vertex_feature.npy\"))\n",
        "vertex_features = preprocessing.scale(vertex_features)\n",
        "\n",
        "embedding_path = os.path.join(file_dir, \"deepwalk.emb_64\")\n",
        "max_vertex_idx = np.max(vertices)\n",
        "embedding = load_w2v_feature(embedding_path, max_vertex_idx)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(779164, 50, 50)\n(779164,)\n(779164, 50, 2)\n(1784073, 7)\n(1784024, 64)\n[1 1]\n"
        }
      ],
      "source": [
        "print(graphs.shape)\n",
        "print(labels.shape)\n",
        "print(influence_features.shape)\n",
        "print(vertex_features.shape)\n",
        "print(embedding.shape)\n",
        "print(labels[:2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class GAT(keras.layers.Layer):\n",
        "    def __init__(self, n_head, f_in, f_out, attn_dropout):\n",
        "        super(GAT, self).__init__()\n",
        "        self.n_head = n_head\n",
        "        w_init = tf.keras.initializers.GlorotUniform()\n",
        "        self.w = tf.Variable(\n",
        "            initial_value=w_init(shape=(n_head, f_in, f_out), dtype=\"float32\"),\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.a_src = tf.Variable(\n",
        "            initial_value=w_init(shape=(n_head, f_out, 1), dtype=\"float32\"),\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.a_dst = tf.Variable(\n",
        "            initial_value=w_init(shape=(n_head, f_out, 1), dtype=\"float32\"),\n",
        "            trainable=True,\n",
        "        )\n",
        "        b_init = tf.zeros_initializer()\n",
        "        self.b = tf.Variable(\n",
        "            initial_value=b_init(shape=(f_out,), dtype=\"float32\"), trainable=True\n",
        "        )\n",
        "        self.dropout = attn_dropout\n",
        "    def call(self, h, adj):\n",
        "   #     h, adj = inputs\n",
        "        bs, n = h.shape[:2]\n",
        "        h_prime = tf.matmul(tf.expand_dims(h,1),self.w)\n",
        "        attn_src = tf.matmul(tf.math.tanh(h_prime),self.a_src)\n",
        "        attn_dst = tf.matmul(tf.math.tanh(h_prime),self.a_dst)\n",
        "        s1 = attn_src.shape\n",
        "        s2 = attn_dst.shape\n",
        "        attn_src_b = tf.broadcast_to(attn_src,[s1[0],s1[1],s1[2],n])\n",
        "        attn_dst_b = tf.broadcast_to(attn_dst,[s2[0],s2[1],s2[2],n])\n",
        "        attn_dst_permute = tf.keras.layers.Permute((1,3,2))(attn_dst_b)\n",
        "        attn = attn_src_b + attn_dst_permute\n",
        "\n",
        "        attn = tf.nn.leaky_relu(attn,alpha=0.2)\n",
        "        ## mask = 1 - tf.expand_dims(adj,1)\n",
        "        ## todo: mask fill\n",
        "        \n",
        "        attn  = tf.nn.softmax(attn,axis=-1)\n",
        "        attn = tf.nn.dropout(attn,self.dropout)\n",
        "        return tf.matmul(attn, h_prime)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tensor(\"feature_1:0\", shape=(32, 50, 2), dtype=float32)\nTensor(\"graph_1:0\", shape=(None, 50, 50), dtype=float32)\n(32, 8, 50, 16)\n(32, 50, 8, 16)\n(32, 50, 128)\n(32, 8, 50, 16)\n(32, 50, 8, 16)\n(32, 50, 128)\n(32, 1, 50, 2)\n(32, 50, 2)\n"
        }
      ],
      "source": [
        "vertices_inputs = keras.Input(shape=(None,),name='vertices')\n",
        "#print(vertices_inputs.op)\n",
        "feature_inputs = keras.Input(shape=(50,2),batch_size=32,name='feature')\n",
        "print(feature_inputs)\n",
        "graph_inputs = keras.Input(shape=(50,50),name='graph')\n",
        "print(graph_inputs)\n",
        "##todo: emb init\n",
        "#emb = keras.layers.Embedding(embedding.shape[0],embedding.shape[1],embeddings_initializer=xxxx)\n",
        "##todo: instance normalization\n",
        "##emb = tfa.layers.InstanceNormalization(emb)\n",
        "#x = keras.layers.Concatenate(feature_inputs,emb)\n",
        "#x = feature_inputs\n",
        "#x = keras.layers.Embedding(vertex_features.shape(0),ertex_features.shape(1), embeddings_initializer=xxx)\n",
        "\n",
        "##todo: multi head\n",
        "#x = keras.layers.AdditiveAttention(x,graph_inputs) \n",
        "        # n_units [2,16,16,2] after add emedding shuld be 2 + 64 + 7 = 73\n",
        "        # n head [8,8,1]\n",
        "        # 8,2,16,0.2\n",
        "        # 8,16*8,16, 0.2\n",
        "        # 1,16*8,2, 0.2\n",
        "\n",
        "x = GAT(8,2,16,0.2)(feature_inputs,graph_inputs) # (32, 8, 50, 16)\n",
        "x = tf.transpose(x,perm=[0,2,1,3])  # (32, 50, 8, 16)\n",
        "x = tf.reshape(x,[32,50,-1])   # (32, 50, 128)\n",
        "# todo: elu(x) + dropout\n",
        "\n",
        "x = GAT(8,16*8,16,0.2)(x,graph_inputs) # (32, 8, 50, 16)\n",
        "x = tf.transpose(x,perm=[0,2,1,3]) # (32, 50, 8, 16)\n",
        "x = tf.reshape(x,[32,50,-1])   # (32, 50, 128)\n",
        "# todo: elu(x) + dropout\n",
        "\n",
        "x = GAT(1,16*8,2,0.2)(x,graph_inputs) ((32, 1, 50, 2))\n",
        "x = tf.reduce_mean(x,axis=1)  # (32, 50, 2)\n",
        "output = tf.nn.softmax(x,name='output')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data. Its structure depends on your model and\n",
        "        # on what you pass to `fit()`.\n",
        "        x, y = data\n",
        "       \n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            y_pred = y_pred[:,-1,:]\n",
        "            # Compute the loss value\n",
        "            # (the loss function is configured in `compile()`)\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "            print(loss)\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        ### realy work?\n",
        "        trainable_vars = [ x for x in filter(lambda i: 'embedding' not in i.name ,trainable_vars)]\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        # Update metrics (includes the metric that tracks the loss)\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = CustomModel(\n",
        "    inputs=[vertices_inputs, feature_inputs, graph_inputs],\n",
        "    outputs=output,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QOsi6b-1CXIn"
      },
      "outputs": [],
      "source": [
        "## pytorch nllloss maybe == tf SparseCategoricalCrossentropy\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adagrad(lr=lr),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"custom_model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nfeature (InputLayer)            [(32, 50, 2)]        0                                            \n__________________________________________________________________________________________________\ngraph (InputLayer)              [(None, 50, 50)]     0                                            \n__________________________________________________________________________________________________\ngat_3 (GAT)                     (32, 8, 50, 16)      528         feature[0][0]                    \n__________________________________________________________________________________________________\ntf_op_layer_Transpose_2 (Tensor [(32, 50, 8, 16)]    0           gat_3[0][0]                      \n__________________________________________________________________________________________________\ntf_op_layer_Reshape_2 (TensorFl [(32, 50, 128)]      0           tf_op_layer_Transpose_2[0][0]    \n__________________________________________________________________________________________________\ngat_4 (GAT)                     (32, 8, 50, 16)      16656       tf_op_layer_Reshape_2[0][0]      \n__________________________________________________________________________________________________\ntf_op_layer_Transpose_3 (Tensor [(32, 50, 8, 16)]    0           gat_4[0][0]                      \n__________________________________________________________________________________________________\ntf_op_layer_Reshape_3 (TensorFl [(32, 50, 128)]      0           tf_op_layer_Transpose_3[0][0]    \n__________________________________________________________________________________________________\ngat_5 (GAT)                     (32, 1, 50, 2)       262         tf_op_layer_Reshape_3[0][0]      \n__________________________________________________________________________________________________\ntf_op_layer_Mean (TensorFlowOpL [(32, 50, 2)]        0           gat_5[0][0]                      \n__________________________________________________________________________________________________\nvertices (InputLayer)           [(None, None)]       0                                            \n__________________________________________________________________________________________________\ntf_op_layer_output_1 (TensorFlo [(32, 50, 2)]        0           tf_op_layer_Mean[0][0]           \n==================================================================================================\nTotal params: 17,446\nTrainable params: 17,446\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "({'vertices': <tf.Tensor 'IteratorGetNext:2' shape=(None, 50) dtype=int64>, 'feature': <tf.Tensor 'IteratorGetNext:0' shape=(None, 50, 2) dtype=float32>, 'graph': <tf.Tensor 'IteratorGetNext:1' shape=(None, 50, 50) dtype=uint8>}, {'tf_op_layer_output_1': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=int64>})\ny_pred shape\n(32, 50, 2)\n(32, 2)\ndata\n{'tf_op_layer_output_1': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=int64>}\nTensor(\"strided_slice:0\", shape=(32, 2), dtype=float32)\nTensor(\"sparse_categorical_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\nVariable:0\n[<tf.Variable 'Variable:0' shape=(8, 2, 16) dtype=float32>, <tf.Variable 'Variable:0' shape=(8, 16, 1) dtype=float32>, <tf.Variable 'Variable:0' shape=(8, 16, 1) dtype=float32>, <tf.Variable 'Variable:0' shape=(16,) dtype=float32>, <tf.Variable 'Variable:0' shape=(8, 128, 16) dtype=float32>, <tf.Variable 'Variable:0' shape=(8, 16, 1) dtype=float32>, <tf.Variable 'Variable:0' shape=(8, 16, 1) dtype=float32>, <tf.Variable 'Variable:0' shape=(16,) dtype=float32>, <tf.Variable 'Variable:0' shape=(1, 128, 2) dtype=float32>, <tf.Variable 'Variable:0' shape=(1, 2, 1) dtype=float32>, <tf.Variable 'Variable:0' shape=(1, 2, 1) dtype=float32>, <tf.Variable 'Variable:0' shape=(2,) dtype=float32>]\n"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "in user code:\n\n    /Users/lsj/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    <ipython-input-39-d84ba0cfec1f>:32 train_step  *\n        print(k.values)\n\n    AttributeError: 'Tensor' object has no attribute 'values'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-fb4ea069fda9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"tf_op_layer_output_1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    /Users/lsj/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    <ipython-input-39-d84ba0cfec1f>:32 train_step  *\n        print(k.values)\n\n    AttributeError: 'Tensor' object has no attribute 'values'\n"
          ]
        }
      ],
      "source": [
        "model.fit(\n",
        "    {\"vertices\": vertices , \"feature\":influence_features , \"graph\": graphs},\n",
        "    {\"tf_op_layer_output\": labels},\n",
        "    epochs=1,\n",
        "    batch_size=32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "custom_training_walkthrough.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit",
      "name": "python_defaultSpec_1595269995667"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
